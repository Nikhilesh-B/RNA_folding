{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd908c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:01:45.978050Z",
     "iopub.status.busy": "2025-05-03T13:01:45.977680Z",
     "iopub.status.idle": "2025-05-03T13:04:34.082544Z",
     "shell.execute_reply": "2025-05-03T13:04:34.081585Z"
    },
    "papermill": {
     "duration": 168.11445,
     "end_time": "2025-05-03T13:04:34.084950",
     "exception": false,
     "start_time": "2025-05-03T13:01:45.970500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.26.3 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.26.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.26.3 which is incompatible.\r\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\r\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\r\n",
      "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming you've mounted your dataset containing the wheels and Protenix code\n",
    "DATASET_PATH = '/kaggle/input/required-presets'\n",
    "\n",
    "# Install dependencies from wheels\n",
    "wheel_path = os.path.join(DATASET_PATH, 'wheels')\n",
    "!pip install -qqq --no-index --find-links {wheel_path} torch numpy pandas scipy rdkit protenix\n",
    "\n",
    "# Add Protenix to Python path\n",
    "protenix_path = os.path.join(DATASET_PATH, 'Protenix')\n",
    "sys.path.append(protenix_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16ab19e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:04:34.098143Z",
     "iopub.status.busy": "2025-05-03T13:04:34.097842Z",
     "iopub.status.idle": "2025-05-03T13:04:34.273156Z",
     "shell.execute_reply": "2025-05-03T13:04:34.272227Z"
    },
    "papermill": {
     "duration": 0.182787,
     "end_time": "2025-05-03T13:04:34.274913",
     "exception": false,
     "start_time": "2025-05-03T13:04:34.092126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  3 13:04:34 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   39C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f175193",
   "metadata": {
    "papermill": {
     "duration": 0.004773,
     "end_time": "2025-05-03T13:04:34.285040",
     "exception": false,
     "start_time": "2025-05-03T13:04:34.280267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959c534b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:04:34.296481Z",
     "iopub.status.busy": "2025-05-03T13:04:34.296121Z",
     "iopub.status.idle": "2025-05-03T13:04:35.273836Z",
     "shell.execute_reply": "2025-05-03T13:04:35.272717Z"
    },
    "papermill": {
     "duration": 0.985597,
     "end_time": "2025-05-03T13:04:35.275671",
     "exception": false,
     "start_time": "2025-05-03T13:04:34.290074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "validation_sequence = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/validation_sequences.csv')\n",
    "validation_labels = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/validation_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39f7be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:04:35.288054Z",
     "iopub.status.busy": "2025-05-03T13:04:35.287748Z",
     "iopub.status.idle": "2025-05-03T13:04:35.421014Z",
     "shell.execute_reply": "2025-05-03T13:04:35.419956Z"
    },
    "papermill": {
     "duration": 0.140929,
     "end_time": "2025-05-03T13:04:35.422498",
     "exception": false,
     "start_time": "2025-05-03T13:04:35.281569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>temporal_cutoff</th>\n",
       "      <th>description</th>\n",
       "      <th>all_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1SCL_A</td>\n",
       "      <td>GGGUGCUCAGUACGAGAGGAACCGCACCC</td>\n",
       "      <td>1995-01-26</td>\n",
       "      <td>THE SARCIN-RICIN LOOP, A MODULAR RNA</td>\n",
       "      <td>&gt;1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1RNK_A</td>\n",
       "      <td>GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU</td>\n",
       "      <td>1995-02-27</td>\n",
       "      <td>THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...</td>\n",
       "      <td>&gt;1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1RHT_A</td>\n",
       "      <td>GGGACUGACGAUCACGCAGUCUAU</td>\n",
       "      <td>1995-06-03</td>\n",
       "      <td>24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...</td>\n",
       "      <td>&gt;1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1HLX_A</td>\n",
       "      <td>GGGAUAACUUCGGUUGUCCC</td>\n",
       "      <td>1995-09-15</td>\n",
       "      <td>P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID</td>\n",
       "      <td>&gt;1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1HMH_E</td>\n",
       "      <td>GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU</td>\n",
       "      <td>1995-12-07</td>\n",
       "      <td>THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...</td>\n",
       "      <td>&gt;1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_id                            sequence temporal_cutoff  \\\n",
       "0    1SCL_A       GGGUGCUCAGUACGAGAGGAACCGCACCC      1995-01-26   \n",
       "1    1RNK_A  GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU      1995-02-27   \n",
       "2    1RHT_A            GGGACUGACGAUCACGCAGUCUAU      1995-06-03   \n",
       "3    1HLX_A                GGGAUAACUUCGGUUGUCCC      1995-09-15   \n",
       "4    1HMH_E  GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU      1995-12-07   \n",
       "\n",
       "                                         description  \\\n",
       "0               THE SARCIN-RICIN LOOP, A MODULAR RNA   \n",
       "1  THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...   \n",
       "2  24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...   \n",
       "3  P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID   \n",
       "4  THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...   \n",
       "\n",
       "                                       all_sequences  \n",
       "0  >1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...  \n",
       "1  >1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...  \n",
       "2  >1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...  \n",
       "3  >1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...  \n",
       "4  >1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv') \n",
    "test_sequences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46f1739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:04:35.436359Z",
     "iopub.status.busy": "2025-05-03T13:04:35.436025Z",
     "iopub.status.idle": "2025-05-03T13:04:35.451565Z",
     "shell.execute_reply": "2025-05-03T13:04:35.450709Z"
    },
    "papermill": {
     "duration": 0.024262,
     "end_time": "2025-05-03T13:04:35.452989",
     "exception": false,
     "start_time": "2025-05-03T13:04:35.428727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc696b1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:04:35.464586Z",
     "iopub.status.busy": "2025-05-03T13:04:35.464342Z",
     "iopub.status.idle": "2025-05-03T13:04:35.486378Z",
     "shell.execute_reply": "2025-05-03T13:04:35.485659Z"
    },
    "papermill": {
     "duration": 0.029372,
     "end_time": "2025-05-03T13:04:35.487874",
     "exception": false,
     "start_time": "2025-05-03T13:04:35.458502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID resname  resid  x_1  y_1  z_1  x_2  y_2  z_2  x_3  y_3  z_3  x_4  \\\n",
       "0  R1107_1       G      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  R1107_2       G      2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  R1107_3       G      3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  R1107_4       G      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  R1107_5       G      5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   y_4  z_4  x_5  y_5  z_5  \n",
       "0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01fabcd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:04:35.501484Z",
     "iopub.status.busy": "2025-05-03T13:04:35.501217Z",
     "iopub.status.idle": "2025-05-03T13:04:35.515585Z",
     "shell.execute_reply": "2025-05-03T13:04:35.514578Z"
    },
    "papermill": {
     "duration": 0.022644,
     "end_time": "2025-05-03T13:04:35.517023",
     "exception": false,
     "start_time": "2025-05-03T13:04:35.494379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source exists: True\n",
      "Target dir exists: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "source = '/kaggle/input/cif-configs/components.v20240608.cif'\n",
    "target = '/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache/components.v20240608.cif'\n",
    "\n",
    "print(\"Source exists:\", os.path.exists(source))\n",
    "print(\"Target dir exists:\", os.path.exists(os.path.dirname(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58602ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:04:35.529094Z",
     "iopub.status.busy": "2025-05-03T13:04:35.528849Z",
     "iopub.status.idle": "2025-05-03T13:04:35.534011Z",
     "shell.execute_reply": "2025-05-03T13:04:35.533274Z"
    },
    "papermill": {
     "duration": 0.012665,
     "end_time": "2025-05-03T13:04:35.535299",
     "exception": false,
     "start_time": "2025-05-03T13:04:35.522634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dir exists: True\n"
     ]
    }
   ],
   "source": [
    "# Make sure the parent directory of the target exists\n",
    "target_dir = os.path.dirname(target)\n",
    "os.makedirs(target_dir, exist_ok=True)  \n",
    "print(\"Target dir exists:\", os.path.exists(os.path.dirname(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b8e8e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:04:35.547426Z",
     "iopub.status.busy": "2025-05-03T13:04:35.547207Z",
     "iopub.status.idle": "2025-05-03T13:46:38.998165Z",
     "shell.execute_reply": "2025-05-03T13:46:38.997286Z"
    },
    "papermill": {
     "duration": 2523.458703,
     "end_time": "2025-05-03T13:46:38.999691",
     "exception": false,
     "start_time": "2025-05-03T13:04:35.540988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created symlink for CCD file\n",
      "Created symlink for RDKIT file\n",
      "Loaded 12 test sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1107: GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [01:52<20:41, 112.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 CIF files for R1107\n",
      "Processing R1108: GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [03:20<16:21, 98.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 CIF files for R1108\n",
      "Processing R1116: CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGGGGUUGUACCCACCCCAGAGGCCCACGUGGCGGCUAGUACUCCGGUAUUGCGGUACCCUUGUACGCCUGUUUUAGCCGCGGGUCCAGGGUUCAAGUCCCUGUUCGGGCGCCA\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1116\n",
      "Found 5 CIF files for R1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [05:23<16:23, 109.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1117v2: UUGGGUUCCCUCACCCCAAUCAUAAAAAGG\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1117v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [06:47<13:15, 99.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 CIF files for R1117v2\n",
      "Processing R1126: GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUUACACCAUGCAACGCAGACCUGUAGAUGCCACGCUAGCCGUGGUGAGGGUCGGGUCCAGAUGUCAUUCGACUUUAACGCGCCUAAGCGUUGAAGGCGUGUUAGAGCAGAUAGUUCGCUAUCUGGGGAGCCUGUUCGCAGGCUCAGGAGCCUUCGGGCUCCUAGCGCUAUUACCCCGGACACCACCGGGCAGACAAGUAAUGGUGCUCCUCGAAUGACUUCUGUUGAGUAGAGUGUGGGCUCCGCGGCUAGUGUGCACCUUAGCGGUGAAUGUCUGACACCGUUAAGGUGGUUACUCUUCGGAGUAACGCCGAGAUUCC\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1126\n",
      "Found 5 CIF files for R1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [11:53<20:17, 173.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1128: GGAAUAUCGUCAUGGUGAUUCGUCACCAUGAGGCUAGAUCUCAUAUCUAGCGCUUUCGAGCGCUAGAGUCCUUAUCUAGCCGGUUUAUACUUUCGAGUGUGAACCCGAUAUUCCGCGGAUCACUAUGAGUCGUUCGCGGCUCAUAGUCCGGCUCAAAGGACAUCAUGGCCUGUUCGCAGGUUGUGAUUAUGAGUGAGCCGGGUAAGGCAUACCGUUCGCGGUAUGUCUUACGAUCCGC\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1128\n",
      "Found 5 CIF files for R1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [14:54<17:38, 176.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1136: GGAUACGUCUACGCUCAGUGACGGACUCUCUUCGGAGAGUCUGACAUCCGAACCAUACACGGAUGUGCCUCGCCGAACAGUCUACGGCGAGCUUAAGCGCUGGGGACGCCCAACGCAUCACAAAGACUGAGUGAUGAACCAGAAGUAUGGACUGGUUGCGUUGGUGGAGACGGUCGGGUCCAGUUCGCUGUCGAGUAGAGUGUGGGCUCCAUCGACGCCGCUUUAAGGUCCCCAAUCGUGGCGUGUCGGCCUGCUUCGGCAGGCACUGGCGCCGGGACCUUGAAGAGAUGAGAUUUCGAUCUCAUCUUUGGGUGUCUCUGGUGCUUGAGGGCCCUGUGUUCGCACAGGGCCGCUCACUGGGUGUGGACGUAUCC\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1136\n",
      "Found 5 CIF files for R1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [20:11<18:31, 222.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1138: GGGAGAGUACUAUUCAGAUGCAGACCGCAAGUUCAGAGCGGUUUGCAUCUAGGGUACGUUUUCGAACGUAUCCUCCGACUAAGUGUAUUCGUAUACUUAGUGCCUUGUGCCUGCUUCGGCAGGCAUGACCCAAAUGUGCCUUUCGGGGCACAUUUCCGGUCAUCCAAGUUCGCUUGGGUGAUGCGGGCGUAUAGGUUCGUCUAUACGUCCGCGUUUUCCGAGAAGAGGUAACUCGGGAAACCGGUCCACGUGACAAAGGUAGAGUUACGUGGAGGGAGCAGCUGCAAAGGGAUAAUGCAGUUGCUGGCUGGAUGCCAGAACUCACGACUGGCAUCUACGGGGAUGGUGCUCUCCCAAUUCUCCAUUUACCGCCGAAUCGACCCCAACGUGAGAGGGGUCGGUUCCCCGAGCAUAGACCAAUAUCCCAGGUUUAUGCUCCCCAACGCUGGACGAACUACCUACGUCUAGCGUUCCGGCAAAUGAGUCAAUACCUCAGACUUAUUUGCGGUGCCUGAGCCUAAACUGAACAUGGGUUCAGGCAUCUUGGCUCCAGUUCGCUGGAGCCGACGGUAGCGCUGCGUUCGCGCAGUGCUAGGGAGCAUCCGUUUUCGAGCGGAUGCUGGGCGGUUGCCUGUUCGCAGGCAAUCGGGCCUACUCAUGAUUCGUCAUGAGUGGUGACAGCGUGAUGUUCGCAUUACGCUGUCGGGUAGAUGGAGAAUU\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1138\n",
      "Found 5 CIF files for R1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [35:19<29:22, 440.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1149: GGACACGAGUAACUCGUCUAUCUUCUGCAGGCUGCUUACGGUUUCGUCCGUGUUGCAGCCGAUCAUCAGCACAUCUAGGUUUCGUCCGGGUGUGACCGAAAGGUAAGAUGGAGAGCCUUGUCCC\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1149\n",
      "Found 5 CIF files for R1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [37:00<16:43, 334.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1156: GGAGCAUCGUGUCUCAAGUGCUUCACGGUCACAAUAUACCGUUUCGUCGGGUGCGUGGCAAUUCGGUGCACAUCAUGUCUUUCGUGGCUGGUGUGGCUCCUCAAGGUGCGAGGGGCAAGUAUAGAGCAGAGCUCC\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1156\n",
      "Found 5 CIF files for R1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [38:49<08:49, 264.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1189: GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGACGAGGGACUGAAGAGUGGGCGGGGUAAUACCCCGCCCCUUUUU\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1189\n",
      "Found 5 CIF files for R1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [40:25<03:33, 213.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R1190: GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGACGAGGGACUGAAGAGUGGGCGGGGUAAUACCCCGCCCCUUUUU\n",
      "RUNNING INFERENCE\n",
      "Running inference for R1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [42:02<00:00, 210.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 CIF files for R1190\n",
      "Created submission file: submission_proteinx.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RNA 3D Structure Prediction and Submission Generator for Kaggle Environment\n",
    "\n",
    "This script:\n",
    "1. Reads RNA sequences from test_sequences.csv\n",
    "2. Creates input JSONs for each sequence\n",
    "3. Runs the Protenix model to predict 3D structures\n",
    "4. Extracts C1' atom coordinates from the output CIF files\n",
    "5. Creates a submission.csv file in the format required\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from biotite.structure.io import pdbx\n",
    "\n",
    "def create_input_json(sequence, target_id):\n",
    "    \"\"\"\n",
    "    Create the input JSON for a single RNA sequence\n",
    "    \"\"\"\n",
    "    input_json = [{\n",
    "        \"sequences\": [\n",
    "            {\n",
    "                \"rnaSequence\": {\n",
    "                    \"sequence\": sequence,\n",
    "                    \"count\": 1,\n",
    "                    \"modifications\": []\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"name\": target_id,\n",
    "        \"covalent_bonds\": []\n",
    "    }]\n",
    "    return input_json\n",
    "\n",
    "def run_inference(input_json_path, output_dir, target_id):\n",
    "    \"\"\"\n",
    "    Run inference using the Protenix model with kaggle-specific paths\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define command with kaggle-specific paths\n",
    "    cmd = [\n",
    "        \"python\", \"/kaggle/input/required-presets/Protenix/runner/inference.py\",\n",
    "        \"--seeds\", \"42\",\n",
    "        \"--dump_dir\", output_dir,\n",
    "        \"--input_json_path\", input_json_path,\n",
    "        \"--model.N_cycle\", \"10\",\n",
    "        \"--sample_diffusion.N_sample\", \"5\",\n",
    "        \"--sample_diffusion.N_step\", \"200\",\n",
    "        \"--load_checkpoint_path\", \"/kaggle/input/base_model/pytorch/default/1/model_v0.2.0.pt\",\n",
    "        \"--use_deepspeed_evo_attention\", \"false\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running inference for {target_id}\")\n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error running inference for {target_id}: {result.stderr}\")\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Exception running inference for {target_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "def extract_c1_coordinates(cif_file_path):\n",
    "    \"\"\"\n",
    "    Extract C1' atom coordinates from a CIF file using biotite\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CIF file using the correct biotite method\n",
    "        with open(cif_file_path, 'r') as f:\n",
    "            cif_data = pdbx.CIFFile.read(f)\n",
    "        \n",
    "        # Get structure from CIF data\n",
    "        atom_array = pdbx.get_structure(cif_data, model=1)\n",
    "        \n",
    "        # Clean atom names and find C1' atoms\n",
    "        atom_names_clean = np.char.strip(atom_array.atom_name.astype(str))\n",
    "        mask_c1 = atom_names_clean == \"C1'\"\n",
    "        c1_atoms = atom_array[mask_c1]\n",
    "        \n",
    "        if len(c1_atoms) == 0:\n",
    "            print(f\"Warning: No C1' atoms found in {cif_file_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Sort by residue ID and return coordinates\n",
    "        sort_indices = np.argsort(c1_atoms.res_id)\n",
    "        c1_atoms_sorted = c1_atoms[sort_indices]\n",
    "        c1_coords = c1_atoms_sorted.coord\n",
    "        \n",
    "        return c1_coords\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting C1' coordinates from {cif_file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_sequence(sequence, target_id, temp_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single RNA sequence and return C1' coordinates\n",
    "    \"\"\"\n",
    "    print(f\"Processing {target_id}: {sequence}\")\n",
    "    \n",
    "    # Create input JSON\n",
    "    input_json = create_input_json(sequence, target_id)\n",
    "    \n",
    "    # Save JSON to temporary file\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    input_json_path = os.path.join(temp_dir, f\"{target_id}_input.json\")\n",
    "    with open(input_json_path, \"w\") as f:\n",
    "        json.dump(input_json, f, indent=4)\n",
    "\n",
    "\n",
    "    print(\"RUNNING INFERENCE\")\n",
    "    # Run inference\n",
    "    success = run_inference(input_json_path, output_dir, target_id)\n",
    "    \n",
    "    if not success:\n",
    "        print(f\"Inference failed for {target_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Find the CIF files for this target\n",
    "    target_prediction_dir = os.path.join(output_dir, target_id, \"seed_42\", \"predictions\")\n",
    "    if not os.path.exists(target_prediction_dir):\n",
    "        print(f\"Prediction directory not found for {target_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Look for CIF files with the pattern {target_id}_seed_42_sample_*.cif\n",
    "    cif_files = sorted(glob.glob(os.path.join(target_prediction_dir, f\"{target_id}_seed_42_sample_*.cif\")))\n",
    "    \n",
    "    # If no CIF files found, return None\n",
    "    if not cif_files:\n",
    "        print(f\"No CIF files found for {target_id}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(cif_files)} CIF files for {target_id}\")\n",
    "    \n",
    "    # Extract C1' coordinates from each CIF file\n",
    "    all_coords = []\n",
    "    for cif_file in cif_files:\n",
    "        coords = extract_c1_coordinates(cif_file)\n",
    "        if coords is not None:\n",
    "            all_coords.append(coords)\n",
    "    \n",
    "    if not all_coords:\n",
    "        print(f\"No valid C1' coordinates found for {target_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure we have 5 models (if we have fewer, duplicate the last one)\n",
    "    while len(all_coords) < 5:\n",
    "        print(f\"Only {len(all_coords)} models found for {target_id}, duplicating last model\")\n",
    "        all_coords.append(all_coords[-1])\n",
    "    \n",
    "    return all_coords[:5]  # Ensure we only have 5 models\n",
    "\n",
    "def create_submission(test_sequences_df, c1_coords_dict, output_file):\n",
    "    \"\"\"\n",
    "    Create the submission CSV file with C1' coordinates\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    # Process each sequence\n",
    "    for _, row in test_sequences_df.iterrows():\n",
    "        target_id = row['target_id']\n",
    "        sequence = row['sequence']\n",
    "        \n",
    "        if target_id not in c1_coords_dict or c1_coords_dict[target_id] is None:\n",
    "            print(f\"No prediction found for {target_id}, using zeros\")\n",
    "            # Create empty predictions (all zeros)\n",
    "            for i, residue in enumerate(sequence):\n",
    "                row_data = {\n",
    "                    'ID': f\"{target_id}_{i+1}\",\n",
    "                    'resname': residue,\n",
    "                    'resid': i+1\n",
    "                }\n",
    "                for model in range(1, 6):\n",
    "                    row_data[f'x_{model}'] = 0.0\n",
    "                    row_data[f'y_{model}'] = 0.0\n",
    "                    row_data[f'z_{model}'] = 0.0\n",
    "                rows.append(row_data)\n",
    "        else:\n",
    "            # Get the 5 models for this target\n",
    "            models = c1_coords_dict[target_id]\n",
    "            \n",
    "            # Create a row for each residue\n",
    "            for i, residue in enumerate(sequence):\n",
    "                row_data = {\n",
    "                    'ID': f\"{target_id}_{i+1}\",\n",
    "                    'resname': residue,\n",
    "                    'resid': i+1\n",
    "                }\n",
    "                \n",
    "                # Add coordinates for each model\n",
    "                for model_idx in range(5):\n",
    "                    if model_idx < len(models) and i < len(models[model_idx]):\n",
    "                        row_data[f'x_{model_idx+1}'] = models[model_idx][i][0]\n",
    "                        row_data[f'y_{model_idx+1}'] = models[model_idx][i][1]\n",
    "                        row_data[f'z_{model_idx+1}'] = models[model_idx][i][2]\n",
    "                    else:\n",
    "                        # If coordinates are not available, use zeros\n",
    "                        row_data[f'x_{model_idx+1}'] = 0.0\n",
    "                        row_data[f'y_{model_idx+1}'] = 0.0\n",
    "                        row_data[f'z_{model_idx+1}'] = 0.0\n",
    "                \n",
    "                rows.append(row_data)\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Created submission file: {output_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function\n",
    "    \"\"\"\n",
    "    # Set up required symlinks for CCD cache as in kaggle_inference.py\n",
    "    # os.makedirs(\"/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache\", exist_ok=True)\n",
    "    \n",
    "    # source_ccd_file = \"/kaggle/input/required-presets/Protenix/release_data/ccd_cache/components.v20240608.cif\"\n",
    "    source_ccd_file = \"/kaggle/input/cif-configs/components.v20240608.cif\"\n",
    "    target_ccd_file = \"/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache/components.v20240608.cif\"\n",
    "    \n",
    "    # source_rdkit_file = \"/kaggle/input/required-presets/Protenix/release_data/ccd_cache/components.v20240608.cif.rdkit_mol.pkl\"\n",
    "    source_rdkit_file = \"/kaggle/input/rdfkit-mol-configs/components.v20240608.cif.rdkit_mol.pkl\"\n",
    "    target_rdkit_file = \"/usr/local/lib/python3.10/dist-packages/release_data/ccd_cache/components.v20240608.cif.rdkit_mol.pkl\"\n",
    "    \n",
    "    # Create the symlinks if the source files exist\n",
    "    if os.path.exists(source_ccd_file) and not os.path.exists(target_ccd_file):\n",
    "        try:\n",
    "            os.symlink(source_ccd_file, target_ccd_file)\n",
    "            print(f\"Created symlink for CCD file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating symlink for CCD file: {e}\")\n",
    "    \n",
    "    if os.path.exists(source_rdkit_file) and not os.path.exists(target_rdkit_file):\n",
    "        try:\n",
    "            os.symlink(source_rdkit_file, target_rdkit_file)\n",
    "            print(f\"Created symlink for RDKIT file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating symlink for RDKIT file: {e}\")\n",
    "    \n",
    "    # Create directories\n",
    "    temp_dir = \"./input\"  # Same as in kaggle_inference.py\n",
    "    output_dir = \"./output\"  # Same as in kaggle_inference.py\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Read test sequences\n",
    "    test_sequences_df = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\")\n",
    "    print(f\"Loaded {len(test_sequences_df)} test sequences\")\n",
    "    \n",
    "    # Process each sequence\n",
    "    c1_coords_dict = {}\n",
    "    for _, row in tqdm(test_sequences_df.iterrows(), total=len(test_sequences_df)):\n",
    "        target_id = row['target_id']\n",
    "        sequence = row['sequence']\n",
    "        \n",
    "        # Check if we already have predictions for this target\n",
    "        target_prediction_dir = os.path.join(output_dir, target_id, \"seed_42\", \"predictions\")\n",
    "        # if os.path.exists(target_prediction_dir):\n",
    "        #     print(f\"Found existing prediction for {target_id}, loading coordinates\")\n",
    "        #     # Extract coordinates from existing predictions\n",
    "        #     cif_files = sorted(glob.glob(os.path.join(target_prediction_dir, f\"{target_id}_seed_42_sample_*.cif\")))\n",
    "            \n",
    "        #     all_coords = []\n",
    "        #     for cif_file in cif_files:\n",
    "        #         coords = extract_c1_coordinates(cif_file)\n",
    "        #         if coords is not None:\n",
    "        #             all_coords.append(coords)\n",
    "            \n",
    "        #     if all_coords:\n",
    "        #         # Ensure we have 5 models\n",
    "        #         while len(all_coords) < 5:\n",
    "        #             all_coords.append(all_coords[-1])\n",
    "        #         c1_coords_dict[target_id] = all_coords[:5]\n",
    "        #         continue\n",
    "        \n",
    "        # Process the sequence if no existing prediction was found or was invalid\n",
    "        c1_coords = process_sequence(sequence, target_id, temp_dir, output_dir)\n",
    "        c1_coords_dict[target_id] = c1_coords\n",
    "    \n",
    "    # Create submission file\n",
    "    create_submission(test_sequences_df, c1_coords_dict, \"submission_proteinx.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e80d937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:39.015858Z",
     "iopub.status.busy": "2025-05-03T13:46:39.015573Z",
     "iopub.status.idle": "2025-05-03T13:46:39.046433Z",
     "shell.execute_reply": "2025-05-03T13:46:39.045644Z"
    },
    "papermill": {
     "duration": 0.040656,
     "end_time": "2025-05-03T13:46:39.047793",
     "exception": false,
     "start_time": "2025-05-03T13:46:39.007137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>37.601820</td>\n",
       "      <td>-16.422558</td>\n",
       "      <td>1.939063</td>\n",
       "      <td>5.824182</td>\n",
       "      <td>16.536963</td>\n",
       "      <td>-10.767471</td>\n",
       "      <td>5.799640</td>\n",
       "      <td>-2.146582</td>\n",
       "      <td>7.439495</td>\n",
       "      <td>-3.425308</td>\n",
       "      <td>4.484353</td>\n",
       "      <td>-7.920562</td>\n",
       "      <td>5.793245</td>\n",
       "      <td>-1.575572</td>\n",
       "      <td>2.599703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>34.191550</td>\n",
       "      <td>-20.335598</td>\n",
       "      <td>3.814997</td>\n",
       "      <td>3.294317</td>\n",
       "      <td>20.006725</td>\n",
       "      <td>-6.981667</td>\n",
       "      <td>8.468418</td>\n",
       "      <td>2.735674</td>\n",
       "      <td>7.844085</td>\n",
       "      <td>-3.573072</td>\n",
       "      <td>3.839163</td>\n",
       "      <td>-13.471598</td>\n",
       "      <td>6.872671</td>\n",
       "      <td>-6.936265</td>\n",
       "      <td>1.316255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>30.570080</td>\n",
       "      <td>-22.294626</td>\n",
       "      <td>7.575865</td>\n",
       "      <td>-0.998172</td>\n",
       "      <td>21.148815</td>\n",
       "      <td>-3.386232</td>\n",
       "      <td>9.344164</td>\n",
       "      <td>7.902585</td>\n",
       "      <td>5.379312</td>\n",
       "      <td>-0.813519</td>\n",
       "      <td>3.626969</td>\n",
       "      <td>-18.383713</td>\n",
       "      <td>5.103741</td>\n",
       "      <td>-12.324585</td>\n",
       "      <td>0.872446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>27.251116</td>\n",
       "      <td>-21.419300</td>\n",
       "      <td>11.730287</td>\n",
       "      <td>-5.714538</td>\n",
       "      <td>20.002113</td>\n",
       "      <td>-0.513947</td>\n",
       "      <td>8.697208</td>\n",
       "      <td>11.990276</td>\n",
       "      <td>1.468656</td>\n",
       "      <td>3.904374</td>\n",
       "      <td>3.269795</td>\n",
       "      <td>-21.252160</td>\n",
       "      <td>1.049839</td>\n",
       "      <td>-16.139956</td>\n",
       "      <td>0.736787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>24.500246</td>\n",
       "      <td>-18.078104</td>\n",
       "      <td>14.983085</td>\n",
       "      <td>-9.839331</td>\n",
       "      <td>16.785517</td>\n",
       "      <td>1.518587</td>\n",
       "      <td>6.182068</td>\n",
       "      <td>14.624467</td>\n",
       "      <td>-2.613430</td>\n",
       "      <td>9.367692</td>\n",
       "      <td>2.357225</td>\n",
       "      <td>-21.938896</td>\n",
       "      <td>-4.140966</td>\n",
       "      <td>-17.947940</td>\n",
       "      <td>0.559772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>R1190_114</td>\n",
       "      <td>U</td>\n",
       "      <td>114</td>\n",
       "      <td>-16.919416</td>\n",
       "      <td>11.680684</td>\n",
       "      <td>-3.029330</td>\n",
       "      <td>16.263908</td>\n",
       "      <td>-1.395315</td>\n",
       "      <td>-13.275238</td>\n",
       "      <td>-3.980381</td>\n",
       "      <td>13.476168</td>\n",
       "      <td>-15.538403</td>\n",
       "      <td>14.525020</td>\n",
       "      <td>7.083041</td>\n",
       "      <td>24.652187</td>\n",
       "      <td>-27.740038</td>\n",
       "      <td>-26.013542</td>\n",
       "      <td>10.710480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>R1190_115</td>\n",
       "      <td>U</td>\n",
       "      <td>115</td>\n",
       "      <td>-21.183908</td>\n",
       "      <td>11.397099</td>\n",
       "      <td>-0.031589</td>\n",
       "      <td>13.675847</td>\n",
       "      <td>-1.947221</td>\n",
       "      <td>-17.721000</td>\n",
       "      <td>-5.106933</td>\n",
       "      <td>18.419048</td>\n",
       "      <td>-14.427042</td>\n",
       "      <td>10.211531</td>\n",
       "      <td>6.039055</td>\n",
       "      <td>21.933180</td>\n",
       "      <td>-29.411844</td>\n",
       "      <td>-21.482206</td>\n",
       "      <td>8.901287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>R1190_116</td>\n",
       "      <td>U</td>\n",
       "      <td>116</td>\n",
       "      <td>-26.323310</td>\n",
       "      <td>12.630419</td>\n",
       "      <td>2.383769</td>\n",
       "      <td>12.456046</td>\n",
       "      <td>-1.530163</td>\n",
       "      <td>-23.144210</td>\n",
       "      <td>-5.578786</td>\n",
       "      <td>23.866405</td>\n",
       "      <td>-15.158010</td>\n",
       "      <td>4.912466</td>\n",
       "      <td>6.434855</td>\n",
       "      <td>19.886086</td>\n",
       "      <td>-32.000587</td>\n",
       "      <td>-16.300838</td>\n",
       "      <td>8.463955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>R1190_117</td>\n",
       "      <td>U</td>\n",
       "      <td>117</td>\n",
       "      <td>-31.403290</td>\n",
       "      <td>14.442698</td>\n",
       "      <td>1.648323</td>\n",
       "      <td>14.130222</td>\n",
       "      <td>-1.355066</td>\n",
       "      <td>-28.282635</td>\n",
       "      <td>-6.390327</td>\n",
       "      <td>28.080353</td>\n",
       "      <td>-18.372074</td>\n",
       "      <td>0.565014</td>\n",
       "      <td>9.196846</td>\n",
       "      <td>17.867617</td>\n",
       "      <td>-32.923050</td>\n",
       "      <td>-11.344921</td>\n",
       "      <td>10.449896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>R1190_118</td>\n",
       "      <td>U</td>\n",
       "      <td>118</td>\n",
       "      <td>-34.698540</td>\n",
       "      <td>15.913908</td>\n",
       "      <td>-2.049342</td>\n",
       "      <td>18.050827</td>\n",
       "      <td>-2.390433</td>\n",
       "      <td>-31.510912</td>\n",
       "      <td>-8.110989</td>\n",
       "      <td>29.696081</td>\n",
       "      <td>-22.967830</td>\n",
       "      <td>-0.841463</td>\n",
       "      <td>13.718763</td>\n",
       "      <td>15.610462</td>\n",
       "      <td>-31.252596</td>\n",
       "      <td>-7.908383</td>\n",
       "      <td>14.022335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID resname  resid        x_1        y_1        z_1        x_2  \\\n",
       "0       R1107_1       G      1  37.601820 -16.422558   1.939063   5.824182   \n",
       "1       R1107_2       G      2  34.191550 -20.335598   3.814997   3.294317   \n",
       "2       R1107_3       G      3  30.570080 -22.294626   7.575865  -0.998172   \n",
       "3       R1107_4       G      4  27.251116 -21.419300  11.730287  -5.714538   \n",
       "4       R1107_5       G      5  24.500246 -18.078104  14.983085  -9.839331   \n",
       "...         ...     ...    ...        ...        ...        ...        ...   \n",
       "2510  R1190_114       U    114 -16.919416  11.680684  -3.029330  16.263908   \n",
       "2511  R1190_115       U    115 -21.183908  11.397099  -0.031589  13.675847   \n",
       "2512  R1190_116       U    116 -26.323310  12.630419   2.383769  12.456046   \n",
       "2513  R1190_117       U    117 -31.403290  14.442698   1.648323  14.130222   \n",
       "2514  R1190_118       U    118 -34.698540  15.913908  -2.049342  18.050827   \n",
       "\n",
       "            y_2        z_2       x_3        y_3        z_3        x_4  \\\n",
       "0     16.536963 -10.767471  5.799640  -2.146582   7.439495  -3.425308   \n",
       "1     20.006725  -6.981667  8.468418   2.735674   7.844085  -3.573072   \n",
       "2     21.148815  -3.386232  9.344164   7.902585   5.379312  -0.813519   \n",
       "3     20.002113  -0.513947  8.697208  11.990276   1.468656   3.904374   \n",
       "4     16.785517   1.518587  6.182068  14.624467  -2.613430   9.367692   \n",
       "...         ...        ...       ...        ...        ...        ...   \n",
       "2510  -1.395315 -13.275238 -3.980381  13.476168 -15.538403  14.525020   \n",
       "2511  -1.947221 -17.721000 -5.106933  18.419048 -14.427042  10.211531   \n",
       "2512  -1.530163 -23.144210 -5.578786  23.866405 -15.158010   4.912466   \n",
       "2513  -1.355066 -28.282635 -6.390327  28.080353 -18.372074   0.565014   \n",
       "2514  -2.390433 -31.510912 -8.110989  29.696081 -22.967830  -0.841463   \n",
       "\n",
       "            y_4        z_4        x_5        y_5        z_5  \n",
       "0      4.484353  -7.920562   5.793245  -1.575572   2.599703  \n",
       "1      3.839163 -13.471598   6.872671  -6.936265   1.316255  \n",
       "2      3.626969 -18.383713   5.103741 -12.324585   0.872446  \n",
       "3      3.269795 -21.252160   1.049839 -16.139956   0.736787  \n",
       "4      2.357225 -21.938896  -4.140966 -17.947940   0.559772  \n",
       "...         ...        ...        ...        ...        ...  \n",
       "2510   7.083041  24.652187 -27.740038 -26.013542  10.710480  \n",
       "2511   6.039055  21.933180 -29.411844 -21.482206   8.901287  \n",
       "2512   6.434855  19.886086 -32.000587 -16.300838   8.463955  \n",
       "2513   9.196846  17.867617 -32.923050 -11.344921  10.449896  \n",
       "2514  13.718763  15.610462 -31.252596  -7.908383  14.022335  \n",
       "\n",
       "[2515 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission_proteinx.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd9e9c7",
   "metadata": {
    "papermill": {
     "duration": 0.007764,
     "end_time": "2025-05-03T13:46:39.063608",
     "exception": false,
     "start_time": "2025-05-03T13:46:39.055844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### New model ensembling with the other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7a1298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:39.079446Z",
     "iopub.status.busy": "2025-05-03T13:46:39.079219Z",
     "iopub.status.idle": "2025-05-03T13:46:40.534942Z",
     "shell.execute_reply": "2025-05-03T13:46:40.534008Z"
    },
    "papermill": {
     "duration": 1.465558,
     "end_time": "2025-05-03T13:46:40.536663",
     "exception": false,
     "start_time": "2025-05-03T13:46:39.071105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c17059b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:40.555048Z",
     "iopub.status.busy": "2025-05-03T13:46:40.554316Z",
     "iopub.status.idle": "2025-05-03T13:46:40.560799Z",
     "shell.execute_reply": "2025-05-03T13:46:40.559950Z"
    },
    "papermill": {
     "duration": 0.016841,
     "end_time": "2025-05-03T13:46:40.562452",
     "exception": false,
     "start_time": "2025-05-03T13:46:40.545611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 0,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 384,\n",
    "    \"batch_size\": 1,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"mixed_precision\": \"bf16\",\n",
    "    \"model_config_path\": \"../working/configs/pairwise.yaml\",  # Adjust path as needed\n",
    "    \"epochs\": 10,\n",
    "    \"cos_epoch\": 5,\n",
    "    \"loss_power_scale\": 1.0,\n",
    "    \"max_cycles\": 1,\n",
    "    \"grad_clip\": 0.1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"d_clamp\": 30,\n",
    "    \"max_len_filter\": 9999999,\n",
    "    \"structural_violation_epoch\": 50,\n",
    "    \"balance_weight\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95d6e1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:40.580521Z",
     "iopub.status.busy": "2025-05-03T13:46:40.580312Z",
     "iopub.status.idle": "2025-05-03T13:46:40.591538Z",
     "shell.execute_reply": "2025-05-03T13:46:40.590627Z"
    },
    "papermill": {
     "duration": 0.020982,
     "end_time": "2025-05-03T13:46:40.592992",
     "exception": false,
     "start_time": "2025-05-03T13:46:40.572010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>temporal_cutoff</th>\n",
       "      <th>description</th>\n",
       "      <th>all_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107</td>\n",
       "      <td>GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...</td>\n",
       "      <td>&gt;7QR4_1|Chain A|U1 small nuclear ribonucleopro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1108</td>\n",
       "      <td>GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUU...</td>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>CPEB3 ribozyme\\nChimpanzee\\nChimpanzee CPEB3 H...</td>\n",
       "      <td>&gt;7QR3_1|Chains A, B|U1 small nuclear ribonucle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1116</td>\n",
       "      <td>CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGG...</td>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>Cloverleaf RNA\\nPoliovirus\\nCrystal Structure ...</td>\n",
       "      <td>&gt;8S95_1|Chain A[auth C]|Lysine tRNA scaffold,P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1117v2</td>\n",
       "      <td>UUGGGUUCCCUCACCCCAAUCAUAAAAAGG</td>\n",
       "      <td>2022-06-03</td>\n",
       "      <td>PreQ1 class I type III riboswitch\\nK. pneumoni...</td>\n",
       "      <td>&gt;8FZA_1|Chains A, B|PreQ1 Riboswitch (30-MER)|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1126</td>\n",
       "      <td>GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUU...</td>\n",
       "      <td>2022-06-11</td>\n",
       "      <td>Traptamer\\nSynthetic\\nAdditional Information: ...</td>\n",
       "      <td>&gt;8TVZ_1|Chain A[auth C]|RNA (363-MER)|syntheti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_id                                           sequence  \\\n",
       "0     R1107  GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...   \n",
       "1     R1108  GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUU...   \n",
       "2     R1116  CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGG...   \n",
       "3   R1117v2                     UUGGGUUCCCUCACCCCAAUCAUAAAAAGG   \n",
       "4     R1126  GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUU...   \n",
       "\n",
       "  temporal_cutoff                                        description  \\\n",
       "0      2022-05-28  CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...   \n",
       "1      2022-05-27  CPEB3 ribozyme\\nChimpanzee\\nChimpanzee CPEB3 H...   \n",
       "2      2022-06-04  Cloverleaf RNA\\nPoliovirus\\nCrystal Structure ...   \n",
       "3      2022-06-03  PreQ1 class I type III riboswitch\\nK. pneumoni...   \n",
       "4      2022-06-11  Traptamer\\nSynthetic\\nAdditional Information: ...   \n",
       "\n",
       "                                       all_sequences  \n",
       "0  >7QR4_1|Chain A|U1 small nuclear ribonucleopro...  \n",
       "1  >7QR3_1|Chains A, B|U1 small nuclear ribonucle...  \n",
       "2  >8S95_1|Chain A[auth C]|Lysine tRNA scaffold,P...  \n",
       "3  >8FZA_1|Chains A, B|PreQ1 Riboswitch (30-MER)|...  \n",
       "4  >8TVZ_1|Chain A[auth C]|RNA (363-MER)|syntheti...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912b61be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:40.609955Z",
     "iopub.status.busy": "2025-05-03T13:46:40.609749Z",
     "iopub.status.idle": "2025-05-03T13:46:40.614946Z",
     "shell.execute_reply": "2025-05-03T13:46:40.614218Z"
    },
    "papermill": {
     "duration": 0.014846,
     "end_time": "2025-05-03T13:46:40.616235",
     "exception": false,
     "start_time": "2025-05-03T13:46:40.601389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RNADataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.tokens={nt:i for i,nt in enumerate('ACGU')}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence=[self.tokens[nt] for nt in (self.data.loc[idx,'sequence'])]\n",
    "        sequence=np.array(sequence)\n",
    "        sequence=torch.tensor(sequence)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return {'sequence':sequence}\n",
    "\n",
    "test_dataset=RNADataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b1e9cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:40.632353Z",
     "iopub.status.busy": "2025-05-03T13:46:40.632077Z",
     "iopub.status.idle": "2025-05-03T13:46:40.635062Z",
     "shell.execute_reply": "2025-05-03T13:46:40.634492Z"
    },
    "papermill": {
     "duration": 0.013011,
     "end_time": "2025-05-03T13:46:40.636665",
     "exception": false,
     "start_time": "2025-05-03T13:46:40.623654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/kaggle/input/ribonanzanet2/pytorch/default/1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88814862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:40.654572Z",
     "iopub.status.busy": "2025-05-03T13:46:40.654330Z",
     "iopub.status.idle": "2025-05-03T13:46:41.518435Z",
     "shell.execute_reply": "2025-05-03T13:46:41.517701Z"
    },
    "papermill": {
     "duration": 0.875041,
     "end_time": "2025-05-03T13:46:41.520046",
     "exception": false,
     "start_time": "2025-05-03T13:46:40.645005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from Network import *\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class finetuned_RibonanzaNet(RibonanzaNet):\n",
    "    def __init__(self, rnet_config, config, pretrained=False):\n",
    "        rnet_config.dropout=0.1\n",
    "        rnet_config.use_grad_checkpoint=True\n",
    "        super(finetuned_RibonanzaNet, self).__init__(rnet_config)\n",
    "        if pretrained:\n",
    "            self.load_state_dict(torch.load(config.pretrained_weight_path,map_location='cpu'))\n",
    "        # self.ct_predictor=nn.Sequential(nn.Linear(64,256),\n",
    "        #                                 nn.ReLU(),\n",
    "        #                                 nn.Linear(256,64),\n",
    "        #                                 nn.ReLU(),\n",
    "        #                                 nn.Linear(64,1)) \n",
    "        self.dropout=nn.Dropout(0.0)\n",
    "\n",
    "        decoder_dim=config.decoder_dim\n",
    "        self.structure_module=[SimpleStructureModule(d_model=decoder_dim, nhead=config.decoder_nhead, \n",
    "                 dim_feedforward=decoder_dim*4, pairwise_dimension=rnet_config.pairwise_dimension, dropout=0.0) for i in range(config.decoder_num_layers)]\n",
    "        self.structure_module=nn.ModuleList(self.structure_module)\n",
    "\n",
    "        self.xyz_embedder=nn.Linear(3,decoder_dim)\n",
    "        self.xyz_norm=nn.LayerNorm(decoder_dim)\n",
    "        self.xyz_predictor=nn.Linear(decoder_dim,3)\n",
    "        \n",
    "        self.adaptor=nn.Sequential(nn.Linear(rnet_config.ninp,decoder_dim),nn.LayerNorm(decoder_dim))\n",
    "\n",
    "        self.distogram_predictor=nn.Sequential(nn.LayerNorm(rnet_config.pairwise_dimension),\n",
    "                                                nn.Linear(rnet_config.pairwise_dimension,40))\n",
    "\n",
    "        self.time_embedder=SinusoidalPosEmb(decoder_dim)\n",
    "\n",
    "        self.time_mlp=nn.Sequential(nn.Linear(decoder_dim,decoder_dim),\n",
    "                                    nn.ReLU(),  \n",
    "                                    nn.Linear(decoder_dim,decoder_dim))\n",
    "        self.time_norm=nn.LayerNorm(decoder_dim)\n",
    "\n",
    "        self.distance2pairwise=nn.Linear(1,rnet_config.pairwise_dimension,bias=False)\n",
    "\n",
    "        self.pair_mlp=nn.Sequential(nn.Linear(rnet_config.pairwise_dimension,rnet_config.pairwise_dimension),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(rnet_config.pairwise_dimension,rnet_config.pairwise_dimension))\n",
    "\n",
    "\n",
    "        #hyperparameters for diffusion\n",
    "        self.n_times = config.n_times\n",
    "\n",
    "        #self.model = model\n",
    "        \n",
    "        # define linear variance schedule(betas)\n",
    "        beta_1, beta_T = config.beta_min, config.beta_max\n",
    "        betas = torch.linspace(start=beta_1, end=beta_T, steps=config.n_times)#.to(device) # follows DDPM paper\n",
    "        self.sqrt_betas = torch.sqrt(betas)\n",
    "                                     \n",
    "        # define alpha for forward diffusion kernel\n",
    "        self.alphas = 1 - betas\n",
    "        self.sqrt_alphas = torch.sqrt(self.alphas)\n",
    "        alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "        self.sqrt_one_minus_alpha_bars = torch.sqrt(1-alpha_bars)\n",
    "        self.sqrt_alpha_bars = torch.sqrt(alpha_bars)\n",
    "\n",
    "        self.data_std=config.data_std\n",
    "\n",
    "\n",
    "    def custom(self, module):\n",
    "        def custom_forward(*inputs):\n",
    "            inputs = module(*inputs)\n",
    "            return inputs\n",
    "        return custom_forward\n",
    "    \n",
    "    def embed_pair_distance(self,inputs):\n",
    "        pairwise_features,xyz=inputs\n",
    "        distance_matrix=xyz[:,None,:,:]-xyz[:,:,None,:]\n",
    "        distance_matrix=(distance_matrix**2).sum(-1).clip(2,37**2).sqrt()\n",
    "        distance_matrix=distance_matrix[:,:,:,None]\n",
    "        pairwise_features=pairwise_features+self.distance2pairwise(distance_matrix)\n",
    "\n",
    "        return pairwise_features\n",
    "\n",
    "    def forward(self,src,xyz,t):\n",
    "        \n",
    "        #with torch.no_grad():\n",
    "        sequence_features, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n",
    "        \n",
    "        distogram=self.distogram_predictor(pairwise_features)\n",
    "\n",
    "        sequence_features=self.adaptor(sequence_features)\n",
    "\n",
    "        decoder_batch_size=xyz.shape[0]\n",
    "        sequence_features=sequence_features.repeat(decoder_batch_size,1,1)\n",
    "        \n",
    "\n",
    "        pairwise_features=pairwise_features.expand(decoder_batch_size,-1,-1,-1)\n",
    "\n",
    "        pairwise_features= checkpoint.checkpoint(self.custom(self.embed_pair_distance), [pairwise_features,xyz],use_reentrant=False)\n",
    "\n",
    "        time_embed=self.time_embedder(t).unsqueeze(1)\n",
    "        tgt=self.xyz_norm(sequence_features+self.xyz_embedder(xyz)+time_embed)\n",
    "\n",
    "        tgt=self.time_norm(tgt+self.time_mlp(tgt))\n",
    "\n",
    "        for layer in self.structure_module:\n",
    "            #tgt=layer([tgt, sequence_features,pairwise_features,xyz,None])\n",
    "            tgt=checkpoint.checkpoint(self.custom(layer),\n",
    "            [tgt, sequence_features,pairwise_features,xyz,None],\n",
    "            use_reentrant=False)\n",
    "            # xyz=xyz+self.xyz_predictor(sequence_features).squeeze(0)\n",
    "            # xyzs.append(xyz)\n",
    "            #print(sequence_features.shape)\n",
    "        \n",
    "        xyz=self.xyz_predictor(tgt).squeeze(0)\n",
    "        #.squeeze(0)\n",
    "\n",
    "        return xyz, distogram\n",
    "    \n",
    "\n",
    "    def denoise(self,sequence_features,pairwise_features,xyz,t):\n",
    "        decoder_batch_size=xyz.shape[0]\n",
    "        sequence_features=sequence_features.expand(decoder_batch_size,-1,-1)\n",
    "        pairwise_features=pairwise_features.expand(decoder_batch_size,-1,-1,-1)\n",
    "\n",
    "        pairwise_features=self.embed_pair_distance([pairwise_features,xyz])\n",
    "\n",
    "        sequence_features=self.adaptor(sequence_features)\n",
    "        time_embed=self.time_embedder(t).unsqueeze(1)\n",
    "        tgt=self.xyz_norm(sequence_features+self.xyz_embedder(xyz)+time_embed)\n",
    "        tgt=self.time_norm(tgt+self.time_mlp(tgt))\n",
    "        #xyz_batch_size=xyz.shape[0]\n",
    "        \n",
    "\n",
    "\n",
    "        for layer in self.structure_module:\n",
    "            tgt=layer([tgt, sequence_features,pairwise_features,xyz,None])\n",
    "            # xyz=xyz+self.xyz_predictor(sequence_features).squeeze(0)\n",
    "            # xyzs.append(xyz)\n",
    "            #print(sequence_features.shape)\n",
    "        xyz=self.xyz_predictor(tgt).squeeze(0)\n",
    "        # print(xyz.shape)\n",
    "        # exit()\n",
    "        return xyz\n",
    "\n",
    "\n",
    "    def extract(self, a, t, x_shape):\n",
    "        \"\"\"\n",
    "            from lucidrains' implementation\n",
    "                https://github.com/lucidrains/denoising-diffusion-pytorch/blob/beb2f2d8dd9b4f2bd5be4719f37082fe061ee450/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py#L376\n",
    "        \"\"\"\n",
    "        b, *_ = t.shape\n",
    "        out = a.gather(-1, t)\n",
    "        return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "    \n",
    "    def scale_to_minus_one_to_one(self, x):\n",
    "        # according to the DDPMs paper, normalization seems to be crucial to train reverse process network\n",
    "        return x * 2 - 1\n",
    "    \n",
    "    def reverse_scale_to_zero_to_one(self, x):\n",
    "        return (x + 1) * 0.5\n",
    "    \n",
    "    def make_noisy(self, x_zeros, t): \n",
    "        # assume we get raw data, so center and scale by 35\n",
    "        x_zeros = x_zeros - torch.nanmean(x_zeros,1,keepdim=True)\n",
    "        x_zeros = x_zeros/self.data_std\n",
    "        #rotate randomly\n",
    "        x_zeros = random_rotation_point_cloud_torch_batch(x_zeros)\n",
    "\n",
    "\n",
    "        # perturb x_0 into x_t (i.e., take x_0 samples into forward diffusion kernels)\n",
    "        epsilon = torch.randn_like(x_zeros).to(x_zeros.device)\n",
    "        \n",
    "        sqrt_alpha_bar = self.extract(self.sqrt_alpha_bars.to(x_zeros.device), t, x_zeros.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars.to(x_zeros.device), t, x_zeros.shape)\n",
    "        \n",
    "        # Let's make noisy sample!: i.e., Forward process with fixed variance schedule\n",
    "        #      i.e., sqrt(alpha_bar_t) * x_zero + sqrt(1-alpha_bar_t) * epsilon\n",
    "        noisy_sample = x_zeros * sqrt_alpha_bar + epsilon * sqrt_one_minus_alpha_bar\n",
    "    \n",
    "        return noisy_sample.detach(), epsilon\n",
    "    \n",
    "    \n",
    "    # def forward(self, x_zeros):\n",
    "    #     x_zeros = self.scale_to_minus_one_to_one(x_zeros)\n",
    "        \n",
    "    #     B, _, _, _ = x_zeros.shape\n",
    "        \n",
    "    #     # (1) randomly choose diffusion time-step\n",
    "    #     t = torch.randint(low=0, high=self.n_times, size=(B,)).long().to(x_zeros.device)\n",
    "        \n",
    "    #     # (2) forward diffusion process: perturb x_zeros with fixed variance schedule\n",
    "    #     perturbed_images, epsilon = self.make_noisy(x_zeros, t)\n",
    "        \n",
    "    #     # (3) predict epsilon(noise) given perturbed data at diffusion-timestep t.\n",
    "    #     pred_epsilon = self.model(perturbed_images, t)\n",
    "        \n",
    "    #     return perturbed_images, epsilon, pred_epsilon\n",
    "    \n",
    "    \n",
    "    def denoise_at_t(self, x_t, sequence_features, pairwise_features, timestep, t):\n",
    "        B, _, _ = x_t.shape\n",
    "        if t > 1:\n",
    "            z = torch.randn_like(x_t).to(sequence_features.device)\n",
    "        else:\n",
    "            z = torch.zeros_like(x_t).to(sequence_features.device)\n",
    "        \n",
    "        # at inference, we use predicted noise(epsilon) to restore perturbed data sample.\n",
    "        epsilon_pred = self.denoise(sequence_features, pairwise_features, x_t, timestep)\n",
    "        \n",
    "        alpha = self.extract(self.alphas.to(x_t.device), timestep, x_t.shape)\n",
    "        sqrt_alpha = self.extract(self.sqrt_alphas.to(x_t.device), timestep, x_t.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars.to(x_t.device), timestep, x_t.shape)\n",
    "        sqrt_beta = self.extract(self.sqrt_betas.to(x_t.device), timestep, x_t.shape)\n",
    "        \n",
    "        # denoise at time t, utilizing predicted noise\n",
    "        x_t_minus_1 = 1 / sqrt_alpha * (x_t - (1-alpha)/sqrt_one_minus_alpha_bar*epsilon_pred) + sqrt_beta*z\n",
    "        \n",
    "        return x_t_minus_1#.clamp(-1., 1)\n",
    "                \n",
    "    def sample(self, src, N):\n",
    "        # start from random noise vector, NxLx3\n",
    "        x_t = torch.randn((N, src.shape[1], 3)).to(src.device)\n",
    "        \n",
    "        # autoregressively denoise from x_T to x_0\n",
    "        #     i.e., generate image from noise, x_T\n",
    "\n",
    "        #first get conditioning\n",
    "        sequence_features, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n",
    "        # sequence_features=sequence_features.expand(N,-1,-1)\n",
    "        # pairwise_features=pairwise_features.expand(N,-1,-1,-1)\n",
    "        distogram=self.distogram_predictor(pairwise_features).squeeze()\n",
    "        distogram=distogram.squeeze()[:,:,2:40]*torch.arange(2,40).float().cuda() \n",
    "        distogram=distogram.sum(-1)  \n",
    "\n",
    "        for t in range(self.n_times-1, -1, -1):\n",
    "            timestep = torch.tensor([t]).repeat_interleave(N, dim=0).long().to(src.device)\n",
    "            x_t = self.denoise_at_t(x_t, sequence_features, pairwise_features, timestep, t)\n",
    "        \n",
    "        # denormalize x_0 into 0 ~ 1 ranged values.\n",
    "        #x_0 = self.reverse_scale_to_zero_to_one(x_t)\n",
    "        x_0 = x_t * self.data_std\n",
    "        return x_0, distogram\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SimpleStructureModule(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, \n",
    "                 dim_feedforward, pairwise_dimension, dropout=0.1,\n",
    "                 ):\n",
    "        super(SimpleStructureModule, self).__init__()\n",
    "        #self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.self_attn = MultiHeadAttention(d_model, nhead, d_model//nhead, d_model//nhead, dropout=dropout)\n",
    "        #self.cross_attn = MultiHeadAttention(d_model, nhead, d_model//nhead, d_model//nhead, dropout=dropout)\n",
    "\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.pairwise2heads=nn.Linear(pairwise_dimension,nhead,bias=False)\n",
    "        self.pairwise_norm=nn.LayerNorm(pairwise_dimension)\n",
    "\n",
    "        #self.distance2heads=nn.Linear(1,nhead,bias=False)\n",
    "        #self.pairwise_norm=nn.LayerNorm(pairwise_dimension)\n",
    "\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "        \n",
    "    def custom(self, module):\n",
    "        def custom_forward(*inputs):\n",
    "            inputs = module(*inputs)\n",
    "            return inputs\n",
    "        return custom_forward\n",
    "\n",
    "    def forward(self, input):\n",
    "        tgt , src,  pairwise_features, pred_t, src_mask = input\n",
    "        \n",
    "        #src = src*src_mask.float().unsqueeze(-1)\n",
    "\n",
    "        pairwise_bias=self.pairwise2heads(self.pairwise_norm(pairwise_features)).permute(0,3,1,2)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #print(pairwise_bias.shape,distance_bias.shape)\n",
    "\n",
    "        #pairwise_bias=pairwise_bias+distance_bias\n",
    "\n",
    "\n",
    "        res=tgt\n",
    "        tgt,attention_weights = self.self_attn(tgt, tgt, tgt, mask=pairwise_bias, src_mask=src_mask)\n",
    "        tgt = res + self.dropout1(tgt)\n",
    "        tgt = self.norm1(tgt)\n",
    "\n",
    "        # print(tgt.shape,src.shape)\n",
    "        # exit()\n",
    "\n",
    "        res=tgt\n",
    "        tgt = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        tgt = res + self.dropout2(tgt)\n",
    "        tgt = self.norm2(tgt)\n",
    "\n",
    "\n",
    "        return tgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "136dec98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:41.538461Z",
     "iopub.status.busy": "2025-05-03T13:46:41.537957Z",
     "iopub.status.idle": "2025-05-03T13:46:44.089294Z",
     "shell.execute_reply": "2025-05-03T13:46:44.088553Z"
    },
    "papermill": {
     "duration": 2.561415,
     "end_time": "2025-05-03T13:46:44.090844",
     "exception": false,
     "start_time": "2025-05-03T13:46:41.529429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing 48 ConvTransformerEncoderLayers\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        self.entries=entries\n",
    "\n",
    "    def print(self):\n",
    "        print(self.entries)\n",
    "\n",
    "def load_config_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return Config(**config)\n",
    "\n",
    "\n",
    "diffusion_config=load_config_from_yaml(\"/kaggle/input/ribonanzanet2-ddpm-v2/diffusion_config.yaml\")\n",
    "rnet_config=load_config_from_yaml(\"/kaggle/input/ribonanzanet2/pytorch/default/1/pairwise.yaml\")\n",
    "\n",
    "model=finetuned_RibonanzaNet(rnet_config,diffusion_config).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43244fe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:44.107841Z",
     "iopub.status.busy": "2025-05-03T13:46:44.107601Z",
     "iopub.status.idle": "2025-05-03T13:46:49.355599Z",
     "shell.execute_reply": "2025-05-03T13:46:49.354820Z"
    },
    "papermill": {
     "duration": 5.257669,
     "end_time": "2025-05-03T13:46:49.356882",
     "exception": false,
     "start_time": "2025-05-03T13:46:44.099213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict=torch.load(\"/kaggle/input/ribonanzanet2-ddpm-v2/RibonanzaNet-DDPM-v2.pt\",map_location='cpu')\n",
    "\n",
    "#get rid of module. from ddp state dict\n",
    "new_state_dict={}\n",
    "\n",
    "for key in state_dict:\n",
    "    new_state_dict[key[7:]]=state_dict[key]\n",
    "\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e66e892d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:46:49.374360Z",
     "iopub.status.busy": "2025-05-03T13:46:49.374067Z",
     "iopub.status.idle": "2025-05-03T13:56:29.473178Z",
     "shell.execute_reply": "2025-05-03T13:56:29.472246Z"
    },
    "papermill": {
     "duration": 580.120043,
     "end_time": "2025-05-03T13:56:29.485174",
     "exception": false,
     "start_time": "2025-05-03T13:46:49.365131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [09:40<00:00, 48.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model.eval()\n",
    "preds=[]\n",
    "for i in tqdm(range(len(test_dataset))):\n",
    "    src=test_dataset[i]['sequence'].long()\n",
    "    src=src.unsqueeze(0).cuda()\n",
    "    target_id=test_data.loc[i,'target_id']\n",
    "\n",
    "    #tmp=[]\n",
    "    predicted_dm=[]\n",
    "    #for _ in range(5):\n",
    "    with torch.no_grad():\n",
    "        xyz,distogram=model.sample(src,5)\n",
    "\n",
    "    preds.append(xyz.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e820545a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:56:29.505242Z",
     "iopub.status.busy": "2025-05-03T13:56:29.504890Z",
     "iopub.status.idle": "2025-05-03T13:56:29.640363Z",
     "shell.execute_reply": "2025-05-03T13:56:29.639438Z"
    },
    "papermill": {
     "duration": 0.147633,
     "end_time": "2025-05-03T13:56:29.642336",
     "exception": false,
     "start_time": "2025-05-03T13:56:29.494703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ID=[]\n",
    "resname=[]\n",
    "resid=[]\n",
    "x=[]\n",
    "y=[]\n",
    "z=[]\n",
    "\n",
    "data=[]\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    #print(test_data.loc[i])\n",
    "\n",
    "    \n",
    "    for j in range(len(test_data.loc[i,'sequence'])):\n",
    "        # ID.append(test_data.loc[i,'sequence_id']+f\"_{j+1}\")\n",
    "        # resname.append(test_data.loc[i,'sequence'][j])\n",
    "        # resid.append(j+1) # 1 indexed\n",
    "        row=[test_data.loc[i,'target_id']+f\"_{j+1}\",\n",
    "             test_data.loc[i,'sequence'][j],\n",
    "             j+1]\n",
    "\n",
    "        for k in range(5):\n",
    "            for kk in range(3):\n",
    "                row.append(preds[i][k][j][kk])\n",
    "        data.append(row)\n",
    "\n",
    "columns=['ID','resname','resid']\n",
    "for i in range(1,6):\n",
    "    columns+=[f\"x_{i}\"]\n",
    "    columns+=[f\"y_{i}\"]\n",
    "    columns+=[f\"z_{i}\"]\n",
    "\n",
    "\n",
    "submission=pd.DataFrame(data,columns=columns)\n",
    "\n",
    "\n",
    "submission\n",
    "submission.to_csv('submission_rnet.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35624a8",
   "metadata": {
    "papermill": {
     "duration": 0.009291,
     "end_time": "2025-05-03T13:56:29.661555",
     "exception": false,
     "start_time": "2025-05-03T13:56:29.652264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Combining our submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02bd35a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T13:56:29.681323Z",
     "iopub.status.busy": "2025-05-03T13:56:29.680949Z",
     "iopub.status.idle": "2025-05-03T13:56:29.755913Z",
     "shell.execute_reply": "2025-05-03T13:56:29.755105Z"
    },
    "papermill": {
     "duration": 0.086812,
     "end_time": "2025-05-03T13:56:29.757604",
     "exception": false,
     "start_time": "2025-05-03T13:56:29.670792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSVs\n",
    "proteinx = pd.read_csv(\"submission_proteinx.csv\")\n",
    "rnet = pd.read_csv(\"submission_rnet.csv\")\n",
    "\n",
    "# Columns to keep from each file\n",
    "common_cols = [\"ID\", \"resname\", \"resid\"]\n",
    "proteinx_coords = [col for col in proteinx.columns if any(col.startswith(f\"{axis}_{i}\") for i in range(1, 4) for axis in ['x', 'y', 'z'])]\n",
    "rnet_coords = [col for col in rnet.columns if any(col.startswith(f\"{axis}_{i}\") for i in range(4, 6) for axis in ['x', 'y', 'z'])]\n",
    "\n",
    "# Build the final dataframe\n",
    "final_submission = pd.concat([\n",
    "    proteinx[common_cols],\n",
    "    proteinx[proteinx_coords],\n",
    "    rnet[rnet_coords]\n",
    "], axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "final_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12024591,
     "isSourceIdPinned": false,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 6896780,
     "sourceId": 11411364,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7195134,
     "sourceId": 11479957,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7221548,
     "sourceId": 11515554,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7222431,
     "sourceId": 11516691,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7305640,
     "sourceId": 11642550,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7305647,
     "sourceId": 11642558,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7313932,
     "sourceId": 11654463,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 311570,
     "modelInstanceId": 290880,
     "sourceId": 348330,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 327042,
     "modelInstanceId": 306564,
     "sourceId": 370268,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3288.087915,
   "end_time": "2025-05-03T13:56:31.092949",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-03T13:01:43.005034",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
