{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from huggingface_hub import hf_hub_download, HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for everything\n",
    "SEED=0\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": SEED,\n",
    "    \"cutoff_date\": \"2022-05-07\",\n",
    "    \"test_cutoff_date\": \"2025-05-10\",\n",
    "    \"max_len\": 384,\n",
    "    \"batch_size\": 1,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"mixed_precision\": \"bf16\",\n",
    "    \"model_config_path\": \"../working/configs/pairwise.yaml\",  # Adjust path as needed\n",
    "    \"epochs\": 10,\n",
    "    \"cos_epoch\": 5,\n",
    "    \"loss_power_scale\": 1.0,\n",
    "    \"max_cycles\": 1,\n",
    "    \"grad_clip\": 0.1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"d_clamp\": 30,\n",
    "    \"max_len_filter\": 9999999,\n",
    "    \"min_len_filter\": 10, \n",
    "    \"structural_violation_epoch\": 50,\n",
    "    \"balance_weight\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T00:35:07.63984Z",
     "iopub.status.busy": "2025-02-27T00:35:07.639563Z",
     "iopub.status.idle": "2025-02-27T00:35:07.643454Z",
     "shell.execute_reply": "2025-02-27T00:35:07.64259Z",
     "shell.execute_reply.started": "2025-02-27T00:35:07.639817Z"
    }
   },
   "source": [
    "# Get data and do some data processing¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_sequences=pd.read_csv(\"./train_sequences_cleaned.csv\")\n",
    "train_labels=pd.read_csv(\"./train_labels_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7KUC_0\n",
       "1         7KUC_0\n",
       "2         7KUC_0\n",
       "3         7KUC_0\n",
       "4         7KUC_0\n",
       "           ...  \n",
       "250452    8Z1F_T\n",
       "250453    8Z1F_T\n",
       "250454    8Z1F_T\n",
       "250455    8Z1F_T\n",
       "250456    8Z1F_T\n",
       "Name: pdb_id, Length: 250457, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[\"pdb_id\"] = train_labels[\"ID\"].apply(lambda x: x.split(\"_\")[0]+'_'+x.split(\"_\")[1])\n",
    "train_labels[\"pdb_id\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1860/1860 [00:22<00:00, 84.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>pdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250371</th>\n",
       "      <td>8Z1F_T_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>103.195999</td>\n",
       "      <td>112.250999</td>\n",
       "      <td>104.455002</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250372</th>\n",
       "      <td>8Z1F_T_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>107.467003</td>\n",
       "      <td>108.984001</td>\n",
       "      <td>106.205002</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250373</th>\n",
       "      <td>8Z1F_T_3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>111.919998</td>\n",
       "      <td>107.942001</td>\n",
       "      <td>109.775002</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250374</th>\n",
       "      <td>8Z1F_T_4</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>114.685997</td>\n",
       "      <td>108.813004</td>\n",
       "      <td>114.404999</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250375</th>\n",
       "      <td>8Z1F_T_5</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>114.921997</td>\n",
       "      <td>110.031998</td>\n",
       "      <td>120.849998</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250452</th>\n",
       "      <td>8Z1F_T_82</td>\n",
       "      <td>U</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250453</th>\n",
       "      <td>8Z1F_T_83</td>\n",
       "      <td>C</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250454</th>\n",
       "      <td>8Z1F_T_84</td>\n",
       "      <td>A</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250455</th>\n",
       "      <td>8Z1F_T_85</td>\n",
       "      <td>U</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250456</th>\n",
       "      <td>8Z1F_T_86</td>\n",
       "      <td>A</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID resname  resid         x_1         y_1         z_1  pdb_id\n",
       "250371   8Z1F_T_1       G      1  103.195999  112.250999  104.455002  8Z1F_T\n",
       "250372   8Z1F_T_2       G      2  107.467003  108.984001  106.205002  8Z1F_T\n",
       "250373   8Z1F_T_3       U      3  111.919998  107.942001  109.775002  8Z1F_T\n",
       "250374   8Z1F_T_4       A      4  114.685997  108.813004  114.404999  8Z1F_T\n",
       "250375   8Z1F_T_5       A      5  114.921997  110.031998  120.849998  8Z1F_T\n",
       "...           ...     ...    ...         ...         ...         ...     ...\n",
       "250452  8Z1F_T_82       U     82         NaN         NaN         NaN  8Z1F_T\n",
       "250453  8Z1F_T_83       C     83         NaN         NaN         NaN  8Z1F_T\n",
       "250454  8Z1F_T_84       A     84         NaN         NaN         NaN  8Z1F_T\n",
       "250455  8Z1F_T_85       U     85         NaN         NaN         NaN  8Z1F_T\n",
       "250456  8Z1F_T_86       A     86         NaN         NaN         NaN  8Z1F_T\n",
       "\n",
       "[86 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>pdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137009</th>\n",
       "      <td>8Z1F_T_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>103.195999</td>\n",
       "      <td>112.250999</td>\n",
       "      <td>104.455002</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137010</th>\n",
       "      <td>8Z1F_T_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>107.467003</td>\n",
       "      <td>108.984001</td>\n",
       "      <td>106.205002</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137011</th>\n",
       "      <td>8Z1F_T_3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>111.919998</td>\n",
       "      <td>107.942001</td>\n",
       "      <td>109.775002</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137012</th>\n",
       "      <td>8Z1F_T_4</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>114.685997</td>\n",
       "      <td>108.813004</td>\n",
       "      <td>114.404999</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137013</th>\n",
       "      <td>8Z1F_T_5</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>114.921997</td>\n",
       "      <td>110.031998</td>\n",
       "      <td>120.849998</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137090</th>\n",
       "      <td>8Z1F_T_82</td>\n",
       "      <td>U</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137091</th>\n",
       "      <td>8Z1F_T_83</td>\n",
       "      <td>C</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137092</th>\n",
       "      <td>8Z1F_T_84</td>\n",
       "      <td>A</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137093</th>\n",
       "      <td>8Z1F_T_85</td>\n",
       "      <td>U</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137094</th>\n",
       "      <td>8Z1F_T_86</td>\n",
       "      <td>A</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8Z1F_T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID resname  resid         x_1         y_1         z_1  pdb_id\n",
       "137009   8Z1F_T_1       G      1  103.195999  112.250999  104.455002  8Z1F_T\n",
       "137010   8Z1F_T_2       G      2  107.467003  108.984001  106.205002  8Z1F_T\n",
       "137011   8Z1F_T_3       U      3  111.919998  107.942001  109.775002  8Z1F_T\n",
       "137012   8Z1F_T_4       A      4  114.685997  108.813004  114.404999  8Z1F_T\n",
       "137013   8Z1F_T_5       A      5  114.921997  110.031998  120.849998  8Z1F_T\n",
       "...           ...     ...    ...         ...         ...         ...     ...\n",
       "137090  8Z1F_T_82       U     82         NaN         NaN         NaN  8Z1F_T\n",
       "137091  8Z1F_T_83       C     83         NaN         NaN         NaN  8Z1F_T\n",
       "137092  8Z1F_T_84       A     84         NaN         NaN         NaN  8Z1F_T\n",
       "137093  8Z1F_T_85       U     85         NaN         NaN         NaN  8Z1F_T\n",
       "137094  8Z1F_T_86       A     86         NaN         NaN         NaN  8Z1F_T\n",
       "\n",
       "[86 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_xyz=[]\n",
    "\n",
    "for pdb_id in tqdm(train_sequences['target_id']):\n",
    "    df = train_labels[train_labels[\"pdb_id\"]==pdb_id]\n",
    "    #break\n",
    "    xyz=df[['x_1','y_1','z_1']].to_numpy().astype('float32')\n",
    "    xyz[xyz<-1e17]=float('Nan');\n",
    "    all_xyz.append(xyz)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in train: 4298\n"
     ]
    }
   ],
   "source": [
    "# filter the data\n",
    "# Filter and process data\n",
    "filter_nan = []\n",
    "max_len = 0\n",
    "for xyz in all_xyz:\n",
    "    if len(xyz) > max_len:\n",
    "        max_len = len(xyz)\n",
    "\n",
    "    #fill -1e18 masked sequences to nans\n",
    "    \n",
    "    #sugar_xyz = np.stack([nt_xyz['sugar_ring'] for nt_xyz in xyz], axis=0)\n",
    "    filter_nan.append((np.isnan(xyz).mean() <= 0.5) & \\\n",
    "                      (len(xyz)<config['max_len_filter']) & \\\n",
    "                      (len(xyz)>config['min_len_filter']))\n",
    "\n",
    "print(f\"Longest sequence in train: {max_len}\")\n",
    "\n",
    "\n",
    "# selecting based on boolean filtering of the non_nan_indices\n",
    "filter_nan = np.array(filter_nan)\n",
    "non_nan_indices = np.arange(len(filter_nan))[filter_nan]\n",
    "\n",
    "train_sequences = train_sequences.loc[non_nan_indices].reset_index(drop=True)\n",
    "all_xyz=[all_xyz[i] for i in non_nan_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pack data into a dictionary\n",
    "\n",
    "data={\n",
    "      \"sequence\":train_sequences['sequence'].to_list(),\n",
    "      \"temporal_cutoff\": train_sequences['temporal_cutoff'].to_list(),\n",
    "      \"description\": train_sequences['description'].to_list(),\n",
    "      \"all_sequences\": train_sequences['all_sequences'].to_list(),\n",
    "      \"xyz\": all_xyz\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train data into train/val/test¶\n",
    "We will simply do a temporal split, because that's how testing is done in structural biology in general (in actual blind tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "all_index = np.arange(len(data['sequence']))\n",
    "cutoff_date = pd.Timestamp(config['cutoff_date'])\n",
    "test_cutoff_date = pd.Timestamp(config['test_cutoff_date'])\n",
    "train_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) <= cutoff_date]\n",
    "test_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) > cutoff_date and pd.Timestamp(d) <= test_cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1157\n",
      "Test size: 341\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_index)}\")\n",
    "print(f\"Test size: {len(test_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get pytorch dataset¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ast import literal_eval\n",
    "\n",
    "def get_ct(bp,s):\n",
    "    ct_matrix=np.zeros((len(s),len(s)))\n",
    "    for b in bp:\n",
    "        ct_matrix[b[0]-1,b[1]-1]=1\n",
    "    return ct_matrix\n",
    "\n",
    "class RNA3D_Dataset(Dataset):\n",
    "    def __init__(self,indices,data):\n",
    "        self.indices=indices\n",
    "        self.data=data\n",
    "        self.tokens={nt:i for i,nt in enumerate('ACGU')}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        idx=self.indices[idx]\n",
    "        sequence=[self.tokens[nt] for nt in (self.data['sequence'][idx])]\n",
    "        sequence=np.array(sequence)\n",
    "        sequence=torch.tensor(sequence)\n",
    "\n",
    "        #get C1' xyz\n",
    "        xyz=self.data['xyz'][idx]\n",
    "        xyz=torch.tensor(np.array(xyz))\n",
    "\n",
    "\n",
    "        if len(sequence)>config['max_len']:\n",
    "            crop_start=np.random.randint(len(sequence)-config['max_len'])\n",
    "            crop_end=crop_start+config['max_len']\n",
    "\n",
    "            sequence=sequence[crop_start:crop_end]\n",
    "            xyz=xyz[crop_start:crop_end]\n",
    "        \n",
    "\n",
    "        return {'sequence':sequence,\n",
    "                'xyz':xyz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=RNA3D_Dataset(train_index,data)\n",
    "val_dataset=RNA3D_Dataset(test_index,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# import numpy as np\n",
    "\n",
    "# # Example: Generate an Nx3 matrix\n",
    "# xyz = train_dataset[200]['xyz']  # Replace this with your actual Nx3 data\n",
    "# N = len(xyz)\n",
    "\n",
    "# for _ in range(2): #plot twice because it doesnt show up on first try for some reason\n",
    "#     # Extract columns\n",
    "#     x, y, z = xyz[:, 0], xyz[:, 1], xyz[:, 2]\n",
    "    \n",
    "#     # Create the 3D scatter plot\n",
    "#     fig = go.Figure(data=[go.Scatter3d(\n",
    "#         x=x, y=y, z=z,\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=5,\n",
    "#             color=z,  # Coloring based on z-value\n",
    "#             colorscale='Viridis',  # Choose a colorscale\n",
    "#             opacity=0.8\n",
    "#         )\n",
    "#     )])\n",
    "    \n",
    "#     # Customize layout\n",
    "#     fig.update_layout(\n",
    "#         scene=dict(\n",
    "#             xaxis_title=\"X\",\n",
    "#             yaxis_title=\"Y\",\n",
    "#             zaxis_title=\"Z\"\n",
    "#         ),\n",
    "#         title=\"3D Scatter Plot\"\n",
    "#     )\n",
    "\n",
    "# fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=config[\"batch_size\"],shuffle=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=config[\"batch_size\"],shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get RibonanzaNet¶\n",
    "We will add a linear layer to predict xyz of C1' atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"./RibonanzaNet2D_Final\")\n",
    "\n",
    "from Network import *\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        self.entries=entries\n",
    "\n",
    "    def print(self):\n",
    "        print(self.entries)\n",
    "\n",
    "def load_config_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return Config(**config)\n",
    "\n",
    "\n",
    "class finetuned_RibonanzaNet(RibonanzaNet):\n",
    "    def __init__(self, config, pretrained=False):\n",
    "        config.dropout=0.1\n",
    "        super(finetuned_RibonanzaNet, self).__init__(config)\n",
    "        if pretrained:\n",
    "            model_path = hf_hub_download(repo_id=\"roos23/RibonanzaNet\",filename=\"RibonanzaNet.pt\")\n",
    "            self.load_state_dict(torch.load(model_path,map_location='cpu'))\n",
    "        # self.ct_predictor=nn.Sequential(nn.Linear(64,256),\n",
    "        #                                 nn.ReLU(),\n",
    "        #                                 nn.Linear(256,64),\n",
    "        #                                 nn.ReLU(),\n",
    "        #                                 nn.Linear(64,1)) \n",
    "        self.dropout=nn.Dropout(0.0)\n",
    "        self.xyz_predictor=nn.Linear(256,3)\n",
    "\n",
    "    def forward(self,src):\n",
    "        \n",
    "        #with torch.no_grad():\n",
    "        sequence_features, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n",
    "        xyz=self.xyz_predictor(sequence_features)\n",
    "\n",
    "        return xyz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing 9 ConvTransformerEncoderLayers\n"
     ]
    }
   ],
   "source": [
    "model=finetuned_RibonanzaNet(load_config_from_yaml(\"./RibonanzaNet2D_Final/configs/pairwise.yaml\"),pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop¶\n",
    "we will use dRMSD loss on the predicted xyz. the loss function is invariant to translations, rotations, and reflections. because dRMSD is invariant to reflections, it cannot distinguish chiral structures, so there may be better loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X,Y,epsilon=1e-4):\n",
    "    return (torch.square(X[:,None]-Y[None,:])+epsilon).sum(-1).sqrt()\n",
    "\n",
    "\n",
    "def dRMSD(pred_x,\n",
    "          pred_y,\n",
    "          gt_x,\n",
    "          gt_y,\n",
    "          epsilon=1e-4,Z=10,d_clamp=None):\n",
    "    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n",
    "    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n",
    "\n",
    "\n",
    "\n",
    "    mask=~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0]).bool()]=False\n",
    "\n",
    "    if d_clamp is not None:\n",
    "        rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).clip(0,d_clamp**2)\n",
    "    else:\n",
    "        rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n",
    "\n",
    "    return rmsd.sqrt().mean()/Z\n",
    "\n",
    "def local_dRMSD(pred_x,\n",
    "          pred_y,\n",
    "          gt_x,\n",
    "          gt_y,\n",
    "          epsilon=1e-4,Z=10,d_clamp=30):\n",
    "    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n",
    "    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n",
    "\n",
    "\n",
    "\n",
    "    mask=(~torch.isnan(gt_dm))*(gt_dm<d_clamp)\n",
    "    mask[torch.eye(mask.shape[0]).bool()]=False\n",
    "\n",
    "\n",
    "\n",
    "    rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n",
    "    # rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).sqrt()/Z\n",
    "    #rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])/Z\n",
    "    return rmsd.sqrt().mean()/Z\n",
    "\n",
    "def dRMAE(pred_x,\n",
    "          pred_y,\n",
    "          gt_x,\n",
    "          gt_y,\n",
    "          epsilon=1e-4,Z=10,d_clamp=None):\n",
    "    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n",
    "    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n",
    "\n",
    "\n",
    "\n",
    "    mask=~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0]).bool()]=False\n",
    "\n",
    "    rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])\n",
    "\n",
    "    return rmsd.mean()/Z\n",
    "\n",
    "import torch\n",
    "\n",
    "def align_svd_mae(input, target, Z=10):\n",
    "    \"\"\"\n",
    "    Aligns the input (Nx3) to target (Nx3) using SVD-based Procrustes alignment\n",
    "    and computes RMSD loss.\n",
    "    \n",
    "    Args:\n",
    "        input (torch.Tensor): Nx3 tensor representing the input points.\n",
    "        target (torch.Tensor): Nx3 tensor representing the target points.\n",
    "    \n",
    "    Returns:\n",
    "        aligned_input (torch.Tensor): Nx3 aligned input.\n",
    "        rmsd_loss (torch.Tensor): RMSD loss.\n",
    "    \"\"\"\n",
    "    assert input.shape == target.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    #mask \n",
    "    mask=~torch.isnan(target.sum(-1))\n",
    "\n",
    "    input=input[mask]\n",
    "    target=target[mask]\n",
    "    \n",
    "    # Compute centroids\n",
    "    centroid_input = input.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input - centroid_input.detach()\n",
    "    target_centered = target - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "\n",
    "    # Compute rotation matrix\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (det(R) = 1, no reflection)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = Vt @ U.T\n",
    "\n",
    "    # Rotate input\n",
    "    aligned_input = (input_centered @ R.T.detach()) + centroid_target.detach()\n",
    "\n",
    "    # # Compute RMSD loss\n",
    "    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n",
    "\n",
    "    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n",
    "    \n",
    "    # return aligned_input, rmsd_loss\n",
    "    return torch.abs(aligned_input-target).mean()/Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "def save_and_push_to_hub(model, save_path, repo_id, hf_token=None):\n",
    "    # Save locally with torch\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"✅ Saved model to {save_path}\")\n",
    "\n",
    "    # Upload to Hugging Face\n",
    "    api = HfApi()\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=save_path,\n",
    "        path_in_repo=save_path,  # or use a cleaner filename\n",
    "        repo_id=repo_id,\n",
    "        token=hf_token,\n",
    "    )\n",
    "    print(f\"🚀 Uploaded model to Hugging Face: {repo_id}/{save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 4.02722543287495 OOMs: 0:  19%|█▉        | 219/1157 [00:20<01:29, 10.53it/s]  "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.amp import GradScaler\n",
    "from mysecrets import HF_secrets\n",
    "\n",
    "epochs=50\n",
    "cos_epoch=35\n",
    "\n",
    "\n",
    "best_loss=np.inf\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0, lr=0.0001) #no weight decay following AF\n",
    "\n",
    "batch_size=config[\"batch_size\"]\n",
    "\n",
    "#for cycle in range(2):\n",
    "\n",
    "criterion=torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "schedule=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(epochs-cos_epoch)*len(train_loader)//batch_size)\n",
    "\n",
    "best_val_loss=99999999999\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    tbar=tqdm(train_loader)\n",
    "    total_loss=0\n",
    "    oom=0\n",
    "    for idx, batch in enumerate(tbar):\n",
    "        #try:\n",
    "        sequence=batch['sequence'].cuda()\n",
    "        gt_xyz=batch['xyz'].cuda().squeeze()\n",
    "\n",
    "        #with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        pred_xyz=model(sequence).squeeze()\n",
    "        \n",
    "        loss=dRMAE(pred_xyz,pred_xyz,gt_xyz,gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "             #local_dRMSD(pred_xyz,pred_xyz,gt_xyz,gt_xyz)\n",
    "\n",
    "        if loss!=loss:\n",
    "            break\n",
    "\n",
    "        \n",
    "        (loss/batch_size).backward()\n",
    "\n",
    "        if (idx+1)%batch_size==0 or idx+1 == len(tbar):\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # scaler.scale(loss/batch_size).backward()\n",
    "            # scaler.unscale_(optimizer)\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "\n",
    "            \n",
    "            if (epoch+1)>cos_epoch:\n",
    "                schedule.step()\n",
    "        #schedule.step()\n",
    "        total_loss+=loss.item()\n",
    "        \n",
    "        tbar.set_description(f\"Epoch {epoch + 1} Loss: {total_loss/(idx+1)} OOMs: {oom}\")\n",
    "\n",
    "        # except Exception:\n",
    "        #     #print(Exception)\n",
    "        #     oom+=1\n",
    "    tbar=tqdm(val_loader)\n",
    "    model.eval()\n",
    "    val_preds=[]\n",
    "    val_loss=0\n",
    "    for idx, batch in enumerate(tbar):\n",
    "        sequence=batch['sequence'].cuda()\n",
    "        gt_xyz=batch['xyz'].cuda().squeeze()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_xyz=model(sequence).squeeze()\n",
    "            loss=dRMAE(pred_xyz,pred_xyz,gt_xyz,gt_xyz)\n",
    "            \n",
    "        val_loss+=loss.item()\n",
    "        val_preds.append([gt_xyz.cpu().numpy(),pred_xyz.cpu().numpy()])\n",
    "    val_loss=val_loss/len(tbar)\n",
    "    print(f\"val loss: {val_loss}\")\n",
    "    \n",
    "    if val_loss<best_val_loss:\n",
    "        best_val_loss=val_loss\n",
    "        best_preds=val_preds\n",
    "        save_and_push_to_hub(model, save_path='Finetuned.pt',repo_id='roos23/RibonanzaFineTuned',hf_token=HF_secrets)\n",
    "\n",
    "save_and_push_to_hub(model, save_path='Finetuned.pt',repo_id='roos23/RibonanzaFineTuned',hf_token=HF_secrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "                                                 "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"svd_cuda_gesvdjBatched\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4437/2106017550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mpred_xyz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Convert for SVD-based loss to float32 to avoid half precision issues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdRMAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_xyz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malign_svd_mae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_xyz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4437/3177811619.py\u001b[0m in \u001b[0;36malign_svd_mae\u001b[0;34m(input, target, Z)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# SVD to find optimal rotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Compute rotation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"svd_cuda_gesvdjBatched\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# from torch.cuda.amp import autocast, GradScaler\n",
    "# import numpy as np\n",
    "\n",
    "# epochs = 50\n",
    "# cos_epoch = 35\n",
    "# batch_size = config[\"batch_size\"]  # Increase batch size if memory permits\n",
    "# best_val_loss = float(\"inf\")\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0, lr=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(epochs - cos_epoch) * len(train_loader))\n",
    "# scaler = torch.amp.GradScaler(\"cuda\")  # Pass device type as positional argument\n",
    "\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "#     tbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "    \n",
    "#     for idx, batch in enumerate(tbar):\n",
    "#         sequence = batch['sequence'].cuda(non_blocking=True)\n",
    "#         gt_xyz = batch['xyz'].cuda(non_blocking=True).squeeze()\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         with torch.amp.autocast(\"cuda\"):\n",
    "#             pred_xyz = model(sequence).squeeze()\n",
    "#             # Convert for SVD-based loss to float32 to avoid half precision issues\n",
    "#             loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "        \n",
    "#         if not torch.isfinite(loss):\n",
    "#             print(f\"Skipping non-finite loss at idx {idx} in epoch {epoch+1}\")\n",
    "#             continue\n",
    "\n",
    "#         scaler.scale(loss).backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "        \n",
    "#         if epoch + 1 > cos_epoch:\n",
    "#             scheduler.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "#         tbar.set_postfix(loss=total_loss / (idx + 1))\n",
    "    \n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     val_preds = []\n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "#             sequence = batch['sequence'].cuda(non_blocking=True)\n",
    "#             gt_xyz = batch['xyz'].cuda(non_blocking=True).squeeze()\n",
    "#             with torch.amp.autocast(\"cuda\"):\n",
    "#                 pred_xyz = model(sequence).squeeze()\n",
    "#                 loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz)\n",
    "#             val_loss += loss.item()\n",
    "#             val_preds.append([gt_xyz.cpu().numpy(), pred_xyz.cpu().numpy()])\n",
    "#     val_loss /= len(val_loader)\n",
    "#     print(f\"Epoch {epoch+1} Validation Loss: {val_loss:.6f}\")\n",
    "    \n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         save_and_push_to_hub(model, save_path='Finetuned.pt',\n",
    "#                              repo_id='roos23/RibonanzaFineTuned',\n",
    "#                              hf_token=HF_secrets)\n",
    "\n",
    "# save_and_push_to_hub(model, save_path='Finetuned.pt',\n",
    "#                      repo_id='roos23/RibonanzaFineTuned',\n",
    "#                      hf_token=HF_secrets)\n",
    "\n",
    "# print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11512973,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 4299272,
     "sourceId": 7639698,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4459124,
     "sourceId": 8318191,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
